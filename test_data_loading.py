#!/usr/bin/env python3
"""
æµ‹è¯•data-action_headæ•°æ®åŠ è½½
"""

import torch
import sys
import os
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

from train import TrajectoryDataset, collate_fn_trajectory

def test_dataset_loading():
    """æµ‹è¯•æ•°æ®é›†åŠ è½½"""
    print("ğŸ§ª æµ‹è¯•data-action_headæ•°æ®é›†åŠ è½½...")
    
    data_root = "/home/data-action_head"
    
    if not os.path.exists(data_root):
        print(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return False
    
    try:
        # åˆ›å»ºè®­ç»ƒæ•°æ®é›†
        train_dataset = TrajectoryDataset(
            data_root=data_root,
            split='train',
            image_size=224,
            train_ratio=0.8
        )
        
        print(f"âœ… è®­ç»ƒæ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(train_dataset)} ä¸ªæ ·æœ¬")
        
        # åˆ›å»ºéªŒè¯æ•°æ®é›†
        val_dataset = TrajectoryDataset(
            data_root=data_root,
            split='val',
            image_size=224,
            train_ratio=0.8
        )
        
        print(f"âœ… éªŒè¯æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(val_dataset)} ä¸ªæ ·æœ¬")
        
        if len(train_dataset) == 0:
            print("âš ï¸  è®­ç»ƒæ•°æ®é›†ä¸ºç©º")
            return False
        
        # æµ‹è¯•å•ä¸ªæ ·æœ¬
        print("ğŸ” æµ‹è¯•å•ä¸ªæ ·æœ¬åŠ è½½...")
        sample = train_dataset[0]
        
        print("æ ·æœ¬æ•°æ®ç»“æ„:")
        for key, value in sample.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.shape} ({value.dtype})")
            else:
                print(f"  {key}: {value} ({type(value).__name__})")
        
        # æµ‹è¯•æ•°æ®åŠ è½½å™¨
        print("ğŸ”„ æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        
        train_loader = torch.utils.data.DataLoader(
            train_dataset,
            batch_size=2,
            shuffle=True,
            num_workers=0,
            collate_fn=collate_fn_trajectory
        )
        
        # è·å–ä¸€ä¸ªæ‰¹æ¬¡
        batch = next(iter(train_loader))
        
        print("æ‰¹æ¬¡æ•°æ®ç»“æ„:")
        for key, value in batch.items():
            if isinstance(value, torch.Tensor):
                print(f"  {key}: {value.shape} ({value.dtype})")
            elif isinstance(value, list):
                print(f"  {key}: list of {len(value)} items")
            else:
                print(f"  {key}: {type(value).__name__}")
        
        # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
        images = batch['images']  # [B, 25, 3, H, W]
        start_layouts = batch['start_layouts']  # [B, 25, 6]
        target_layouts = batch['target_layouts']  # [B, 25, 6]
        element_masks = batch['element_masks']  # [B, 25]
        
        print(f"âœ… å›¾ç‰‡æ•°æ®å½¢çŠ¶æ­£ç¡®: {images.shape}")
        print(f"âœ… èµ·å§‹å¸ƒå±€å½¢çŠ¶æ­£ç¡®: {start_layouts.shape}")
        print(f"âœ… ç›®æ ‡å¸ƒå±€å½¢çŠ¶æ­£ç¡®: {target_layouts.shape}")
        print(f"âœ… å…ƒç´ æ©ç å½¢çŠ¶æ­£ç¡®: {element_masks.shape}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  å›¾ç‰‡åƒç´ å€¼èŒƒå›´: [{images.min():.3f}, {images.max():.3f}]")
        print(f"  èµ·å§‹å¸ƒå±€å€¼èŒƒå›´: [{start_layouts.min():.3f}, {start_layouts.max():.3f}]")
        print(f"  ç›®æ ‡å¸ƒå±€å€¼èŒƒå›´: [{target_layouts.min():.3f}, {target_layouts.max():.3f}]")
        print(f"  æœ‰æ•ˆå…ƒç´ æ•°é‡: {element_masks.sum(dim=1)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_trajectory_data():
    """æµ‹è¯•è½¨è¿¹æ•°æ®"""
    print("ğŸ§ª æµ‹è¯•è½¨è¿¹æ•°æ®ç»“æ„...")
    
    data_root = Path("/home/data-action_head")
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰è½¨è¿¹æ–‡ä»¶çš„ç›®å½•
    for poster_dir in data_root.iterdir():
        if poster_dir.is_dir():
            trajectory_file = poster_dir / 'trajectories.pkl'
            if trajectory_file.exists():
                print(f"ğŸ“‚ æ£€æŸ¥è½¨è¿¹æ–‡ä»¶: {trajectory_file}")
                
                try:
                    import pickle
                    with open(trajectory_file, 'rb') as f:
                        trajectories = pickle.load(f)
                    
                    print(f"âœ… è½¨è¿¹æ–‡ä»¶åŠ è½½æˆåŠŸ")
                    print(f"  å™ªå£°æ°´å¹³: {list(trajectories.keys())}")
                    
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªå™ªå£°æ°´å¹³çš„æ•°æ®
                    first_key = list(trajectories.keys())[0]
                    traj_data = trajectories[first_key]
                    
                    print(f"  {first_key} æ•°æ®ç»“æ„:")
                    for key, value in traj_data.items():
                        if isinstance(value, torch.Tensor):
                            print(f"    {key}: {value.shape}")
                        else:
                            print(f"    {key}: {type(value).__name__}")
                    
                    return True
                    
                except Exception as e:
                    print(f"âŒ è½¨è¿¹æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                    continue
    
    print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„è½¨è¿¹æ–‡ä»¶")
    return False

def main():
    print("=== data-action_head æ•°æ®åŠ è½½æµ‹è¯• ===")
    print()
    
    success = True
    
    # æµ‹è¯•è½¨è¿¹æ•°æ®
    if not test_trajectory_data():
        success = False
    
    print()
    
    # æµ‹è¯•æ•°æ®é›†åŠ è½½
    if not test_dataset_loading():
        success = False
    
    print()
    
    if success:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åŠ è½½æ­£å¸¸å·¥ä½œã€‚")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†:")
        print("   python train.py --config config_data_action_head.json --mode train")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œè·¯å¾„ã€‚")
    
    return success

if __name__ == "__main__":
    main()
